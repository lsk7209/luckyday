/**
 * Cron ì‘ì—… í•¸ë“¤ëŸ¬
 * Cloudflare Workers Cron Triggers
 */

import { Env } from './index';

// Cron ì‘ì—… íƒ€ì…
export interface CronJob {
  name: string;
  schedule: string; // cron í‘œí˜„ì‹
  handler: (env: Env) => Promise<void>;
  enabled: boolean;
}

// ë“±ë¡ëœ Cron ì‘ì—…ë“¤
export const cronJobs: CronJob[] = [
  {
    name: 'sitemap-refresh',
    schedule: '0 */6 * * *', // 6ì‹œê°„ë§ˆë‹¤
    handler: handleSitemapRefresh,
    enabled: true,
  },
  {
    name: 'index-submission',
    schedule: '0 2 * * *', // ë§¤ì¼ ì˜¤ì „ 2ì‹œ
    handler: handleIndexSubmission,
    enabled: true,
  },
  {
    name: 'analytics-aggregation',
    schedule: '0 3 * * *', // ë§¤ì¼ ì˜¤ì „ 3ì‹œ
    handler: handleAnalyticsAggregation,
    enabled: true,
  },
  {
    name: 'broken-link-scan',
    schedule: '0 4 * * 1', // ë§¤ì£¼ ì›”ìš”ì¼ ì˜¤ì „ 4ì‹œ
    handler: handleBrokenLinkScan,
    enabled: true,
  },
  {
    name: 'content-refresh-queue',
    schedule: '*/30 * * * *', // 30ë¶„ë§ˆë‹¤
    handler: handleContentRefreshQueue,
    enabled: true,
  },
  {
    name: 'dream-popularity-update',
    schedule: '30 3 * * *', // ë§¤ì¼ ì˜¤ì „ 3ì‹œ 30ë¶„
    handler: handleDreamPopularityUpdate,
    enabled: true,
  },
  {
    name: 'dream-relation-rebuild',
    schedule: '0 4 * * *', // ë§¤ì¼ ì˜¤ì „ 4ì‹œ
    handler: handleDreamRelationRebuild,
    enabled: true,
  },
  {
    name: 'search-log-cleanup',
    schedule: '0 5 * * 0', // ë§¤ì£¼ ì¼ìš”ì¼ ì˜¤ì „ 5ì‹œ
    handler: handleSearchLogCleanup,
    enabled: true,
  },
];

// ë©”ì¸ Cron í•¸ë“¤ëŸ¬
export async function handleCron(event: ScheduledEvent, env: Env) {
  const cronTime = event.cron;

  console.log(`ğŸ”„ Cron job triggered: ${cronTime}`);

  try {
    // ì‹¤í–‰í•  ì‘ì—… ì°¾ê¸°
    const job = cronJobs.find(job =>
      job.enabled && matchesCronPattern(job.schedule, cronTime)
    );

    if (job) {
      console.log(`ğŸš€ Executing cron job: ${job.name}`);
      await job.handler(env);
      console.log(`âœ… Cron job completed: ${job.name}`);
    } else {
      console.log(`âš ï¸  No matching cron job found for: ${cronTime}`);
    }
  } catch (error) {
    console.error(`âŒ Cron job failed:`, error);

    // ì—ëŸ¬ ë¡œê¹… (ì‹¤ì œë¡œëŠ” ì™¸ë¶€ ë¡œê¹… ì„œë¹„ìŠ¤ë¡œ ì „ì†¡)
    await logCronError(env, cronTime, error);
  }
}

// Cron íŒ¨í„´ ë§¤ì¹­ (ë‹¨ìˆœí™”ëœ ë²„ì „)
function matchesCronPattern(pattern: string, cronTime: string): boolean {
  // ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” cron-parser ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš© ê¶Œì¥
  // ì—¬ê¸°ì„œëŠ” ê°„ë‹¨í•œ ë§¤ì¹­ ë¡œì§
  const [minute, hour, day, month, dayOfWeek] = pattern.split(' ');

  // í˜„ì¬ ì‹œê°„ ì •ë³´ (cronTimeì—ì„œ ì¶”ì¶œ)
  // ì‹¤ì œë¡œëŠ” cronTimeì„ íŒŒì‹±í•´ì„œ ë¹„êµí•´ì•¼ í•¨
  // ì—¬ê¸°ì„œëŠ” ê°„ë‹¨í•œ êµ¬í˜„

  return true; // ëª¨ë“  íŒ¨í„´ì— ëŒ€í•´ true ë°˜í™˜ (ì‹¤ì œ êµ¬í˜„ í•„ìš”)
}

// ì‚¬ì´íŠ¸ë§µ ê°±ì‹  ì‘ì—… (ê¿ˆ í•´ëª½ í¬í•¨)
async function handleSitemapRefresh(env: Env) {
  console.log('ğŸ”„ Refreshing sitemaps...');

  try {
    // ëª¨ë“  ì½˜í…ì¸  íƒ€ì…ì— ëŒ€í•œ ì‚¬ì´íŠ¸ë§µ ìƒì„±
    const contentTypes = ['blog', 'guide', 'utility'];

    for (const type of contentTypes) {
      await generateSitemap(env, type);
    }

    // ê¿ˆ í•´ëª½ ì‚¬ì´íŠ¸ë§µ ìƒì„±
    await generateDreamSitemap(env);

    // ë©”ì¸ ì‚¬ì´íŠ¸ë§µ ê°±ì‹ 
    await generateMainSitemap(env);

    console.log('âœ… Sitemaps refreshed successfully');
  } catch (error) {
    console.error('âŒ Sitemap refresh failed:', error);
    throw error;
  }
}

// ê¿ˆ í•´ëª½ ì‚¬ì´íŠ¸ë§µ ìƒì„±
async function generateDreamSitemap(env: Env) {
  const dreams = await env.DB.prepare(`
    SELECT slug, last_updated FROM dream_symbol
    ORDER BY popularity DESC
  `).all<{ slug: string; last_updated: string }>();

  const urls = (dreams.results || []).map(dream => ({
    loc: `https://luckyday.pages.dev/dream/${dream.slug}`,
    lastmod: dream.last_updated,
    changefreq: 'weekly',
    priority: '0.8',
  }));

  // XML ìƒì„± ë° R2ì— ì €ì¥
  const sitemapXml = generateSitemapXml(urls);
  await env.STORAGE.put('sitemaps/dreams.xml', sitemapXml, {
    httpMetadata: {
      contentType: 'application/xml',
    },
  });
}

// ìƒ‰ì¸ ì œì¶œ ì‘ì—…
async function handleIndexSubmission(env: Env) {
  console.log('ğŸ”„ Submitting URLs to search engines...');

  try {
    // ëŒ€ê¸° ì¤‘ì¸ ìƒ‰ì¸ ì œì¶œ ì‘ì—… ì¡°íšŒ
    const pendingUrls = await env.DB.prepare(`
      SELECT url, provider FROM index_submissions
      WHERE status = 'pending' AND retry_count < 3
      ORDER BY submitted_at ASC
      LIMIT 50
    `).all();

    for (const row of pendingUrls.results || []) {
      const { url, provider } = row as any;

      try {
        await submitToSearchEngine(env, url, provider);
        await updateSubmissionStatus(env, url, provider, 'submitted');
      } catch (error) {
        console.error(`Failed to submit ${url} to ${provider}:`, error);
        await incrementRetryCount(env, url, provider);
      }
    }

    console.log(`âœ… Submitted ${pendingUrls.results?.length || 0} URLs`);
  } catch (error) {
    console.error('âŒ Index submission failed:', error);
    throw error;
  }
}

// ë¶„ì„ ë°ì´í„° ì§‘ê³„ ì‘ì—…
async function handleAnalyticsAggregation(env: Env) {
  console.log('ğŸ”„ Aggregating analytics data...');

  const yesterday = new Date();
  yesterday.setDate(yesterday.getDate() - 1);
  const dateStr = yesterday.toISOString().split('T')[0];

  try {
    // ì¼ì¼ í˜ì´ì§€ í†µê³„ ì§‘ê³„
    await env.DB.exec(`
      INSERT OR REPLACE INTO page_daily_stats (page, date, views, unique_views, bounce_rate, avg_session_duration)
      SELECT
        page,
        DATE(timestamp) as date,
        COUNT(*) as views,
        COUNT(DISTINCT session_id) as unique_views,
        AVG(CASE WHEN event_type = 'bounce' THEN 1 ELSE 0 END) as bounce_rate,
        AVG(session_duration) as avg_session_duration
      FROM analytics_events
      WHERE DATE(timestamp) = ?
      GROUP BY page, DATE(timestamp)
    `, [dateStr]);

    // ì¼ì¼ ì±„ë„ í†µê³„ ì§‘ê³„
    await env.DB.exec(`
      INSERT OR REPLACE INTO channel_daily_stats (channel, date, sessions, users, page_views, bounce_rate)
      SELECT
        COALESCE(utm_source, 'direct') as channel,
        DATE(timestamp) as date,
        COUNT(DISTINCT session_id) as sessions,
        COUNT(DISTINCT user_id) as users,
        COUNT(*) as page_views,
        AVG(CASE WHEN event_type = 'bounce' THEN 1 ELSE 0 END) as bounce_rate
      FROM analytics_events
      WHERE DATE(timestamp) = ?
      GROUP BY COALESCE(utm_source, 'direct'), DATE(timestamp)
    `, [dateStr]);

    console.log('âœ… Analytics data aggregated');
  } catch (error) {
    console.error('âŒ Analytics aggregation failed:', error);
    throw error;
  }
}

// ê¹¨ì§„ ë§í¬ ìŠ¤ìº” ì‘ì—…
async function handleBrokenLinkScan(env: Env) {
  console.log('ğŸ”„ Scanning for broken links...');

  try {
    // ëª¨ë“  ì½˜í…ì¸ ì—ì„œ ë§í¬ ì¶”ì¶œ ë° ê²€ì¦
    const content = await env.DB.prepare(`
      SELECT id, body FROM content WHERE status = 'published'
    `).all();

    const brokenLinks: Array<{ contentId: number; url: string; status: number }> = [];

    for (const row of content.results || []) {
      const { id, body } = row as any;
      const links = extractLinksFromContent(body);

      for (const url of links) {
        try {
          const response = await fetch(url, { method: 'HEAD' });
          if (!response.ok) {
            brokenLinks.push({ contentId: id, url, status: response.status });
          }
        } catch (error) {
          brokenLinks.push({ contentId: id, url, status: 0 });
        }
      }
    }

    // ê¹¨ì§„ ë§í¬ ë¡œê¹…
    for (const link of brokenLinks) {
      console.warn(`Broken link found in content ${link.contentId}: ${link.url} (${link.status})`);
    }

    console.log(`âœ… Found ${brokenLinks.length} broken links`);
  } catch (error) {
    console.error('âŒ Broken link scan failed:', error);
    throw error;
  }
}

// ì½˜í…ì¸  ë¦¬í”„ë ˆì‹œ í ì²˜ë¦¬
async function handleContentRefreshQueue(env: Env) {
  console.log('ğŸ”„ Processing content refresh queue...');

  try {
    // ëŒ€ê¸° ì¤‘ì¸ ì‘ì—… ì¡°íšŒ
    const jobs = await env.DB.prepare(`
      SELECT id, payload FROM jobs
      WHERE status = 'pending' AND kind = 'content_refresh'
      ORDER BY priority DESC, created_at ASC
      LIMIT 10
    `).all();

    for (const job of jobs.results || []) {
      const { id, payload } = job as any;
      const { contentId, action } = JSON.parse(payload);

      try {
        await processContentRefresh(env, contentId, action);
        await updateJobStatus(env, id, 'completed');
      } catch (error) {
        console.error(`Content refresh failed for job ${id}:`, error);
        await updateJobStatus(env, id, 'failed', error.message);
      }
    }

    console.log(`âœ… Processed ${jobs.results?.length || 0} content refresh jobs`);
  } catch (error) {
    console.error('âŒ Content refresh queue processing failed:', error);
    throw error;
  }
}

// í—¬í¼ í•¨ìˆ˜ë“¤
async function generateSitemap(env: Env, type: string) {
  // ì‚¬ì´íŠ¸ë§µ ìƒì„± ë¡œì§
  const content = await env.DB.prepare(`
    SELECT slug, updated_at FROM content
    WHERE type = ? AND status = 'published'
    ORDER BY updated_at DESC
  `).bind(type).all();

  const urls = content.results?.map((row: any) => ({
    loc: `https://your-domain.com/${type}/${row.slug}`,
    lastmod: row.updated_at,
    changefreq: type === 'blog' ? 'weekly' : 'monthly',
    priority: type === 'blog' ? '0.8' : '0.6',
  })) || [];

  // XML ìƒì„± ë° R2ì— ì €ì¥
  const sitemapXml = generateSitemapXml(urls);
  await env.STORAGE.put(`sitemaps/${type}.xml`, sitemapXml, {
    httpMetadata: {
      contentType: 'application/xml',
    },
  });
}

async function generateMainSitemap(env: Env) {
  const sitemaps = [
    'https://your-domain.com/sitemap-blog.xml',
    'https://your-domain.com/sitemap-guide.xml',
    'https://your-domain.com/sitemap-utility.xml',
  ];

  const sitemapXml = generateSitemapIndexXml(sitemaps);
  await env.STORAGE.put('sitemap.xml', sitemapXml, {
    httpMetadata: {
      contentType: 'application/xml',
    },
  });
}

async function submitToSearchEngine(env: Env, url: string, provider: string) {
  const endpoints = {
    google: 'https://www.google.com/ping?sitemap=',
    bing: 'https://www.bing.com/ping?sitemap=',
    indexnow: 'https://api.indexnow.org/indexnow',
  };

  if (provider === 'indexnow') {
    // IndexNow API í˜¸ì¶œ
    const response = await fetch(endpoints.indexnow, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({
        host: 'your-domain.com',
        key: env.INDEXNOW_KEY,
        keyLocation: 'https://your-domain.com/indexnow-key.txt',
        urlList: [url],
      }),
    });
    if (!response.ok) throw new Error(`IndexNow submission failed: ${response.status}`);
  } else {
    // ì¼ë°˜ ping ì„œë¹„ìŠ¤
    const sitemapUrl = `${endpoints[provider as keyof typeof endpoints]}https://your-domain.com/sitemap.xml`;
    const response = await fetch(sitemapUrl);
    if (!response.ok) throw new Error(`Ping failed: ${response.status}`);
  }
}

function extractLinksFromContent(content: string): string[] {
  const linkRegex = /https?:\/\/[^\s<>"']+/g;
  return content.match(linkRegex) || [];
}

function generateSitemapXml(urls: any[]): string {
  const urlElements = urls.map(url => `
    <url>
      <loc>${url.loc}</loc>
      <lastmod>${url.lastmod}</lastmod>
      <changefreq>${url.changefreq}</changefreq>
      <priority>${url.priority}</priority>
    </url>
  `).join('');

  return `<?xml version="1.0" encoding="UTF-8"?>
<urlset xmlns="http://www.sitemaps.org/schemas/sitemap/0.9">
  ${urlElements}
</urlset>`;
}

function generateSitemapIndexXml(sitemaps: string[]): string {
  const sitemapElements = sitemaps.map(url => `
    <sitemap>
      <loc>${url}</loc>
      <lastmod>${new Date().toISOString()}</lastmod>
    </sitemap>
  `).join('');

  return `<?xml version="1.0" encoding="UTF-8"?>
<sitemapindex xmlns="http://www.sitemaps.org/schemas/sitemap/0.9">
  ${sitemapElements}
</sitemapindex>`;
}

// ê¿ˆ ì¸ê¸°ë„ ì—…ë°ì´íŠ¸ ì‘ì—…
async function handleDreamPopularityUpdate(env: Env) {
  console.log('ğŸ”„ Updating dream popularity...');

  try {
    // ìµœê·¼ ê²€ìƒ‰ ë¡œê·¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì¸ê¸°ë„ ì—…ë°ì´íŠ¸
    const searchLogs = await env.DB.prepare(`
      SELECT q, COUNT(*) as count
      FROM search_log
      WHERE ts >= datetime('now', '-7 days')
      GROUP BY q
      ORDER BY count DESC
    `).all<{ q: string; count: number }>();

    for (const log of searchLogs.results || []) {
      // ê²€ìƒ‰ì–´ê°€ í¬í•¨ëœ ê¿ˆë“¤ì˜ ì¸ê¸°ë„ ì¦ê°€
      await env.DB.prepare(`
        UPDATE dream_symbol
        SET popularity = popularity + ?
        WHERE name LIKE ? OR summary LIKE ? OR tags LIKE ?
      `).bind(
        Math.min(log.count * 5, 100), // ìµœëŒ€ 100ì  ì¦ê°€
        `%${log.q}%`,
        `%${log.q}%`,
        `%${log.q}%`
      ).run();
    }

    console.log(`âœ… Updated popularity for ${searchLogs.results?.length || 0} dreams`);
  } catch (error) {
    console.error('âŒ Dream popularity update failed:', error);
    throw error;
  }
}

// ê¿ˆ ê´€ê³„ ê·¸ë˜í”„ ì¬ê³„ì‚° ì‘ì—…
async function handleDreamRelationRebuild(env: Env) {
  console.log('ğŸ”„ Rebuilding dream relations...');

  try {
    // ê¸°ì¡´ ê´€ê³„ ì‚­ì œ (ì„ íƒì‚¬í•­ - ì™„ì „ ì¬êµ¬ì¶• ì‹œ)
    // await env.DB.prepare('DELETE FROM dream_relation').run();

    // ê¿ˆ ì‹¬ë³¼ë“¤ì„ ëª¨ë‘ ì¡°íšŒ
    const dreams = await env.DB.prepare('SELECT slug, category, tags FROM dream_symbol').all<{
      slug: string;
      category: string;
      tags: string;
    }>();

    const relations: Array<{ from: string; to: string; weight: number }> = [];

    for (const dream of dreams.results || []) {
      const tags = JSON.parse(dream.tags || '[]') as string[];

      // ê°™ì€ ì¹´í…Œê³ ë¦¬ì˜ ë‹¤ë¥¸ ê¿ˆë“¤ê³¼ ê´€ê³„ ìƒì„±
      const relatedDreams = (dreams.results || []).filter(d =>
        d.slug !== dream.slug && (
          d.category === dream.category ||
          (JSON.parse(d.tags || '[]') as string[]).some(tag => tags.includes(tag))
        )
      );

      for (const related of relatedDreams.slice(0, 5)) {
        const relatedTags = JSON.parse(related.tags || '[]') as string[];
        const commonTags = tags.filter(t => relatedTags.includes(t));
        const weight = 0.3 + (commonTags.length * 0.15) + (related.category === dream.category ? 0.2 : 0);

        relations.push({
          from: dream.slug,
          to: related.slug,
          weight: Math.min(weight, 1.0)
        });
      }
    }

    // ê´€ê³„ ì €ì¥ (INSERT OR REPLACE)
    for (const rel of relations) {
      await env.DB.prepare(`
        INSERT OR REPLACE INTO dream_relation (from_slug, to_slug, weight)
        VALUES (?, ?, ?)
      `).bind(rel.from, rel.to, rel.weight).run();
    }

    console.log(`âœ… Rebuilt ${relations.length} dream relations`);
  } catch (error) {
    console.error('âŒ Dream relation rebuild failed:', error);
    throw error;
  }
}

// ê²€ìƒ‰ ë¡œê·¸ ì •ë¦¬ ì‘ì—…
async function handleSearchLogCleanup(env: Env) {
  console.log('ğŸ”„ Cleaning up search logs...');

  try {
    // 90ì¼ ì´ìƒ ëœ ê²€ìƒ‰ ë¡œê·¸ ì‚­ì œ
    const result = await env.DB.prepare(`
      DELETE FROM search_log
      WHERE ts < datetime('now', '-90 days')
    `).run();

    console.log(`âœ… Cleaned up ${result.meta.changes || 0} old search logs`);
  } catch (error) {
    console.error('âŒ Search log cleanup failed:', error);
    throw error;
  }
}

// ê¸°íƒ€ í—¬í¼ í•¨ìˆ˜ë“¤ì€ ìƒëµ...
